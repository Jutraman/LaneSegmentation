{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import lmdb\n",
    "import random\n",
    "import torch\n",
    "import colorsys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from imgaug import augmenters as iaa\n",
    "import shutil\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from flask import Flask, render_template, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# process labels\n",
    "def encode_labels(color_mask):\n",
    "    encode_mask = np.zeros((color_mask.shape[0], color_mask.shape[1]))\n",
    "    # 0\n",
    "    id_train = {0:[0, 249, 255, 213, 206, 207, 211, 208,216,215,218, 219,232, 202, 231,230,228,229,233,212,223],\n",
    "                1:[200, 204, 209], 2: [201,203], 3:[217], 4:[210], 5:[214],\n",
    "                6:[220,221,222,224,225,226], 7:[205,227,250]}\n",
    "    for i in range(8):\n",
    "        for item in id_train[i]:\n",
    "            encode_mask[color_mask == item] = i\n",
    "\n",
    "    return encode_mask\n",
    "\n",
    "\n",
    "def decode_labels(labels):\n",
    "    deocde_mask = np.zeros((labels.shape[0], labels.shape[1]), dtype='uint8')\n",
    "    # 0\n",
    "    deocde_mask[labels == 0] = 0\n",
    "    # 1\n",
    "    deocde_mask[labels == 1] = 204\n",
    "    # 2\n",
    "    deocde_mask[labels == 2] = 203\n",
    "    # 3\n",
    "    deocde_mask[labels == 3] = 217\n",
    "    # 4\n",
    "    deocde_mask[labels == 4] = 210\n",
    "    # 5\n",
    "    deocde_mask[labels == 5] = 214\n",
    "    # 6\n",
    "    deocde_mask[labels == 6] = 224\n",
    "    # 7\n",
    "    deocde_mask[labels == 7] = 227\n",
    "\n",
    "    return deocde_mask\n",
    "\n",
    "\n",
    "def decode_color_labels(labels):\n",
    "    decode_mask = np.zeros((3, labels.shape[0], labels.shape[1]), dtype='uint8')\n",
    "    # 0\n",
    "    decode_mask[0][labels == 0] = 0\n",
    "    decode_mask[1][labels == 0] = 0\n",
    "    decode_mask[2][labels == 0] = 0\n",
    "    # 1\n",
    "    decode_mask[0][labels == 1] = 70\n",
    "    decode_mask[1][labels == 1] = 130\n",
    "    decode_mask[2][labels == 1] = 180\n",
    "    # 2\n",
    "    decode_mask[0][labels == 2] = 0\n",
    "    decode_mask[1][labels == 2] = 0\n",
    "    decode_mask[2][labels == 2] = 142\n",
    "    # 3\n",
    "    decode_mask[0][labels == 3] = 153\n",
    "    decode_mask[1][labels == 3] = 153\n",
    "    decode_mask[2][labels == 3] = 153\n",
    "    # 4\n",
    "    decode_mask[0][labels == 4] = 128\n",
    "    decode_mask[1][labels == 4] = 64\n",
    "    decode_mask[2][labels == 4] = 128\n",
    "    # 5\n",
    "    decode_mask[0][labels == 5] = 190\n",
    "    decode_mask[1][labels == 5] = 153\n",
    "    decode_mask[2][labels == 5] = 153\n",
    "    # 6\n",
    "    decode_mask[0][labels == 6] = 0\n",
    "    decode_mask[1][labels == 6] = 0\n",
    "    decode_mask[2][labels == 6] = 230\n",
    "    # 7\n",
    "    decode_mask[0][labels == 7] = 255\n",
    "    decode_mask[1][labels == 7] = 128\n",
    "    decode_mask[2][labels == 7] = 0\n",
    "\n",
    "    return decode_mask\n",
    "\n",
    "\n",
    "def class_colors(num_classes, bright=True):\n",
    "    \"\"\"\n",
    "    based on the class id to choose a centrial color to show them\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / np.float (num_classes), 1, brightness) for i in range (num_classes)]\n",
    "    color_map = list (map (lambda c: colorsys.hsv_to_rgb (*c), hsv))\n",
    "    color_map = np.array(color_map)\n",
    "\n",
    "    return color_map\n",
    "\n",
    "\n",
    "def verify_labels(labels):\n",
    "    pixels = [0]\n",
    "    for x in range(labels.shape[0]):\n",
    "        for y in range(labels.shape[1]):\n",
    "            pixel = labels[x, y]\n",
    "            if pixel not in pixels:\n",
    "                pixels.append(pixel)\n",
    "    print('The Labels Has Value:', pixels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# crop the image to discard useless parts\n",
    "def crop_resize_data(image, label=None, image_size=(1024, 384), offset=690):\n",
    "    \"\"\"\n",
    "    Attention:\n",
    "    h,w,c = image.shape\n",
    "    cv2.resize(image,(w,h))\n",
    "    \"\"\"\n",
    "    roi_image = image[offset:, :]\n",
    "    if label is not None:\n",
    "        roi_label = label[offset:, :]\n",
    "        train_image = cv2.resize(roi_image, image_size, interpolation=cv2.INTER_LINEAR)\n",
    "        train_label = cv2.resize(roi_label, image_size, interpolation=cv2.INTER_NEAREST)\n",
    "        return train_image, train_label\n",
    "    else:\n",
    "        train_image = cv2.resize(roi_image, image_size, interpolation=cv2.INTER_LINEAR)\n",
    "        return train_image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LaneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        super(LaneDataset, self).__init__()\n",
    "\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.paths = [line.strip().split(', ') for line in lines]\n",
    "        self.images = [path[0] for path in self.paths][:16]\n",
    "        self.labels = [path[1] for path in self.paths][:16]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        train_img = cv2.imread(self.images[idx])\n",
    "        train_mask = cv2.imread(self.labels[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        train_img, train_mask = crop_resize_data(train_img, train_mask)\n",
    "        # Encode\n",
    "        train_mask = encode_labels(train_mask)\n",
    "        sample = [train_img.copy(), train_mask.copy()]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class LaneDatasetLMDB(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, lmdb_path, transform=None):\n",
    "        super(LaneDatasetLMDB, self).__init__()\n",
    "\n",
    "        self.env = lmdb.open(lmdb_path)\n",
    "        self.txn = self.env.begin(write=False)\n",
    "        with open(csv_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            self.paths = [line.strip().split(', ') for line in lines]\n",
    "        self.images = [path[0] for path in self.paths]\n",
    "        self.labels = [path[1] for path in self.paths]\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __del__(self):\n",
    "        self.env.close()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        image_bytes = self.txn.get(self.images[idx].encode())\n",
    "        image_bytes = np.array(bytearray(image_bytes), dtype=np.uint8)\n",
    "        mask_bytes = self.txn.get(self.labels[idx].encode())\n",
    "        mask_bytes = np.array(bytearray(mask_bytes), dtype=np.uint8)\n",
    "        train_img= cv2.imdecode(image_bytes, cv2.IMREAD_COLOR)\n",
    "        train_mask = cv2.imdecode(mask_bytes, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        train_img, train_mask = crop_resize_data(train_img, train_mask)\n",
    "        # Encode\n",
    "        train_mask = encode_labels(train_mask)\n",
    "        sample = [train_img.copy(), train_mask.copy()]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# pixel augmentation\n",
    "class ImageAug(object):\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample\n",
    "        if np.random.uniform(0,1) > 0.5:\n",
    "            seq = iaa.Sequential([iaa.OneOf([\n",
    "                iaa.AdditiveGaussianNoise(scale=(0, 0.2 * 255)),\n",
    "                iaa.Sharpen(alpha=(0.1, 0.3), lightness=(0.7, 1.3)),\n",
    "                iaa.GaussianBlur(sigma=(0, 1.0))])])\n",
    "            image = seq.augment_image(image)\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# deformation augmentation\n",
    "class DeformAug(object):\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample\n",
    "        seq = iaa.Sequential([iaa.CropAndPad(percent=(-0.05, 0.1))])\n",
    "        seg_to = seq.to_deterministic()\n",
    "        image = seg_to.augment_image(image)\n",
    "        mask = seg_to.augment_image(mask)\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ScaleAug(object):\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample\n",
    "        scale = random.uniform(0.7, 1.5)\n",
    "        h, w, _ = image.shape\n",
    "        aug_image = image.copy()\n",
    "        aug_mask = mask.copy()\n",
    "        aug_image = cv2.resize(aug_image, (int (scale * w), int (scale * h)))\n",
    "        aug_mask = cv2.resize(aug_mask, (int (scale * w), int (scale * h)))\n",
    "        if (scale < 1.0):\n",
    "            new_h, new_w, _ = aug_image.shape\n",
    "            pre_h_pad = int((h - new_h) / 2)\n",
    "            pre_w_pad = int((w - new_w) / 2)\n",
    "            pad_list = [[pre_h_pad, h - new_h - pre_h_pad], [pre_w_pad, w - new_w - pre_w_pad], [0, 0]]\n",
    "            aug_image = np.pad(aug_image, pad_list, mode=\"constant\")\n",
    "            aug_mask = np.pad(aug_mask, pad_list[:2], mode=\"constant\")\n",
    "        if (scale > 1.0):\n",
    "            new_h, new_w, _ = aug_image.shape\n",
    "            pre_h_crop = int ((new_h - h) / 2)\n",
    "            pre_w_crop = int ((new_w - w) / 2)\n",
    "            post_h_crop = h + pre_h_crop\n",
    "            post_w_crop = w + pre_w_crop\n",
    "            aug_image = aug_image[pre_h_crop:post_h_crop, pre_w_crop:post_w_crop]\n",
    "            aug_mask = aug_mask[pre_h_crop:post_h_crop, pre_w_crop:post_w_crop]\n",
    "        return aug_image, aug_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CutOut(object):\n",
    "    def __init__(self, mask_size, p):\n",
    "        self.mask_size = mask_size\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample\n",
    "        mask_size_half = self.mask_size // 2\n",
    "        offset = 1 if self.mask_size % 2 == 0 else 0\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        cxmin, cxmax = mask_size_half, w + offset - mask_size_half\n",
    "        cymin, cymax = mask_size_half, h + offset - mask_size_half\n",
    "        cx = np.random.randint(cxmin, cxmax)\n",
    "        cy = np.random.randint(cymin, cymax)\n",
    "        xmin, ymin = cx - mask_size_half, cy - mask_size_half\n",
    "        xmax, ymax = xmin + self.mask_size, ymin + self.mask_size\n",
    "        xmin, ymin, xmax, ymax = max(0, xmin), max(0, ymin), min(w, xmax), min(h, ymax)\n",
    "        if np.random.uniform(0, 1) < self.p:\n",
    "            image[ymin:ymax, xmin:xmax] = (0, 0, 0)\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        image, mask = sample\n",
    "        image = np.transpose(image,(2,0,1))\n",
    "        image = image.astype(np.float32)\n",
    "        mask = mask.astype(np.long)\n",
    "        return {'image': torch.from_numpy(image.copy()),\n",
    "                'mask': torch.from_numpy(mask.copy())}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def expand_resize_data(prediction=None, submission_size=(3384, 1710), offset=690):\n",
    "    pred_mask = decode_labels(prediction)\n",
    "    expand_mask = cv2.resize(pred_mask, (submission_size[0], submission_size[1] - offset), interpolation=cv2.INTER_NEAREST)\n",
    "    submission_mask = np.zeros((submission_size[1], submission_size[0]), dtype='uint8')\n",
    "    submission_mask[offset:, :] = expand_mask\n",
    "    return submission_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def expand_resize_color_data(prediction=None, submission_size=(3384, 1710), offset=690):\n",
    "    color_pred_mask = decode_color_labels(prediction)\n",
    "    color_pred_mask = np.transpose(color_pred_mask, (1, 2, 0))\n",
    "    color_expand_mask = cv2.resize(color_pred_mask, (submission_size[0], submission_size[1] - offset), interpolation=cv2.INTER_NEAREST)\n",
    "    color_submission_mask = np.zeros((submission_size[1], submission_size[0], 3), dtype='uint8')\n",
    "    color_submission_mask[offset:, :, :] = color_expand_mask\n",
    "    return color_submission_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data_list_fns = ['data_list/train.csv', 'data_list/val.csv']\n",
    "data_list_fns = ['crop_imgs/img_list.csv']\n",
    "\n",
    "keys = []\n",
    "for data_list_fn in data_list_fns:\n",
    "    with open(data_list_fn, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        keys += [k for line in lines for k in line.strip().split(', ')]\n",
    "\n",
    "#env = lmdb.open('small_dataset_lmdb', map_size=int(1e9))\n",
    "env = lmdb.open('crop_imgs_lmdb', map_size=int(1e9))\n",
    "txn = env.begin(write=True)\n",
    "for key in tqdm(keys):\n",
    "    with open(key, 'rb') as f:\n",
    "        img_bytes = f.read()\n",
    "    txn.put(key.encode(), img_bytes)\n",
    "txn.commit()\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# test reading\n",
    "test = False\n",
    "if test:\n",
    "    env = lmdb.open('small_dataset_lmdb')\n",
    "    txn = env.begin(write=False)\n",
    "    random.shuffle(keys)\n",
    "    for key in keys:\n",
    "        img_bytes = txn.get(key.encode())\n",
    "        img_bytes = np.array(bytearray(img_bytes), dtype=np.uint8)\n",
    "        if key.endswith('.jpg'):\n",
    "            img = cv2.imdecode(img_bytes, cv2.IMREAD_COLOR)\n",
    "        elif key.endswith('.png'):\n",
    "            img = cv2.imdecode(img_bytes, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            print('Unknown image type: %s' % key)\n",
    "            exit()\n",
    "        img = cv2.resize(img, (img.shape[1]//3, img.shape[0]//3))\n",
    "        cv2.imshow('show', img)\n",
    "        key = cv2.waitKey(0)\n",
    "        if 27 == key:\n",
    "            break\n",
    "    env.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MySoftmaxCrossEntropyLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, nbclasses):\n",
    "        super(MySoftmaxCrossEntropyLoss, self).__init__()\n",
    "        self.nbclasses = nbclasses\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        if inputs.dim() > 2:\n",
    "            inputs = inputs.view(inputs.size(0), inputs.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            inputs = inputs.transpose(1, 2)  # N,C,H*W => N,H*W,C\n",
    "            inputs = inputs.contiguous().view(-1, self.nbclasses)  # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1)\n",
    "        return nn.CrossEntropyLoss(reduction=\"mean\")(inputs, target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_iou(pred, gt, result):\n",
    "    \"\"\"\n",
    "    pred : [N, H, W]\n",
    "    gt: [N, H, W]\n",
    "    \"\"\"\n",
    "    pred = pred.cpu().numpy()\n",
    "    gt = gt.cpu().numpy()\n",
    "    for i in range(8):\n",
    "        single_gt = gt==i\n",
    "        single_pred = pred==i\n",
    "        temp_tp = np.sum(single_gt * single_pred)\n",
    "        temp_ta = np.sum(single_pred) + np.sum(single_gt) - temp_tp\n",
    "        result[\"TP\"][i] += temp_tp\n",
    "        result[\"TA\"][i] += temp_ta\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    # model config\n",
    "    OUTPUT_STRIDE = 16\n",
    "    ASPP_OUTDIM = 256\n",
    "    SHORTCUT_DIM = 48\n",
    "    SHORTCUT_KERNEL = 1\n",
    "    NUM_CLASSES = 8\n",
    "\n",
    "    # train config\n",
    "    EPOCHS = 10\n",
    "    WEIGHT_DECAY = 1.0e-4\n",
    "    SAVE_PATH = \"logs\"\n",
    "    BASE_LR = 1e-3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def write_csv(data_list, csv_fn):\n",
    "    with open(csv_fn, 'w') as f:\n",
    "        for image_path, label_path in tqdm(data_list, 'Write csv'):\n",
    "            f.write('%s, %s\\n' % (image_path, label_path))\n",
    "\n",
    "image_list = []\n",
    "label_list = []\n",
    "\n",
    "image_dirs = ['../dataset/round1/train/Road%02d/ColorImage_road%02d' % (i, i) for i in range(2, 5)] +\n",
    "             ['../dataset/round2/train/ColorImage_road%02d' % i for i in range(2, 5)]\n",
    "label_dirs = ['../dataset/round1/train/Gray_Label/Label_road%02d' % i for i in range(2, 5)] +\n",
    "             ['../dataset/round2/train/Gray_Label/Label_road%02d' % i for i in range(2, 5)]\n",
    "image_label_dirs = list(zip(image_dirs, label_dirs))\n",
    "out_dir = 'data_list'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "for image_dir, label_dir in tqdm(image_label_dirs, desc='Read paths'):\n",
    "    image_root = os.path.join(image_dir, 'ColorImage')\n",
    "    label_root = os.path.join(label_dir, 'Label')\n",
    "    # Record\n",
    "    for record_folder in sorted(os.listdir(image_root)):\n",
    "        record_path = os.path.join(image_root, record_folder)\n",
    "        label_record_path = os.path.join(label_root, record_folder)\n",
    "        assert os.path.exists(label_record_path)\n",
    "        # Camera\n",
    "        for camera_folder in sorted(os.listdir(record_path)):\n",
    "            camera_path = os.path.join(record_path, camera_folder)\n",
    "            label_camera_path = os.path.join(label_record_path, camera_folder)\n",
    "            assert os.path.exists(label_camera_path)\n",
    "            # Image\n",
    "            for image_fn in sorted(os.listdir(camera_path)):\n",
    "                image_path = os.path.join(camera_path, image_fn)\n",
    "                label_path = os.path.join(label_camera_path, image_fn[:-4] + '_bin.png')\n",
    "                assert os.path.exists(label_path)\n",
    "                image_list.append(image_path)\n",
    "                label_list.append(label_path)\n",
    "\n",
    "\n",
    "assert len(image_list) == len(label_list),\n",
    "    \"The length of image dataset is {}, and label is {}\".format(len(image_list), len(label_list))\n",
    "image_label_list = list(zip(image_list, label_list))\n",
    "\n",
    "train_list = []\n",
    "val_list = []\n",
    "val_keywords = ['Record001', 'Record002', 'Record003']\n",
    "for image_path, label_path in tqdm(image_label_list, desc='Split train/val'):\n",
    "    is_val = False\n",
    "    for val_filter in val_keywords:\n",
    "        if val_filter in image_path:\n",
    "            val_list.append((image_path, label_path))\n",
    "            is_val = True\n",
    "            break\n",
    "    if not is_val:\n",
    "        train_list.append((image_path, label_path))\n",
    "write_csv(train_list, os.path.join(out_dir, 'train.csv'))\n",
    "write_csv(val_list, os.path.join(out_dir, 'val.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch,out_ch, kernel_size=3, padding=1, stride=1):\n",
    "        super(Block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch,out_ch, kernel_size=3, padding=1, stride=1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_ch)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(self.relu1(self.bn1(x)))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_chans, out_chans):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        assert out_chans % 4 == 0\n",
    "        self.block1 = ResBlock(in_chans, int(out_chans / 4), kernel_size=1, padding=0)\n",
    "        self.block2 = ResBlock(int(out_chans / 4), int(out_chans / 4), kernel_size=3, padding=1)\n",
    "        self.block3 = ResBlock(int(out_chans / 4), out_chans, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class DownBottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, stride=2):\n",
    "        super(DownBottleneck, self).__init__()\n",
    "        assert out_chans % 4 == 0\n",
    "        self.block1 = ResBlock(in_chans, int(out_chans / 4), kernel_size=1, padding=0, stride=stride)\n",
    "        self.conv1 = nn.Conv2d(in_chans, out_chans, kernel_size=1, padding=0, stride=stride)\n",
    "        self.block2 = ResBlock(int(out_chans / 4), int(out_chans / 4), kernel_size=3, padding=1)\n",
    "        self.block3 = ResBlock(int(out_chans / 4), out_chans, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.conv1(x)\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "def make_layers(in_channels, layer_list, name=\"vgg\"):\n",
    "    layers = []\n",
    "    if name == \"vgg\":\n",
    "        for v in layer_list:\n",
    "            layers += [Block(in_channels, v)]\n",
    "            in_channels = v\n",
    "    elif name == \"resnet\":\n",
    "        layers += [DownBottleneck(in_channels, layer_list[0])]\n",
    "        in_channels = layer_list[0]\n",
    "        for v in layer_list[1:]:\n",
    "            layers += [Bottleneck(in_channels, v)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self, in_channels, layer_list, net_name):\n",
    "        super(Layer, self).__init__()\n",
    "        self.layer = make_layers(in_channels, layer_list, name=net_name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer(x)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, rate=1):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, 1, 1, padding=0, dilation=rate, bias=True),\n",
    "            nn.BatchNorm2d(out_chans),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=6 * rate, dilation=6 * rate, bias=True),\n",
    "            nn.BatchNorm2d(out_chans),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=12 * rate, dilation=12 * rate, bias=True),\n",
    "            nn.BatchNorm2d(out_chans),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, 3, 1, padding=18 * rate, dilation=18 * rate, bias=True),\n",
    "            nn.BatchNorm2d(out_chans),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.branch5_avg = nn.AdaptiveAvgPool2d(1)\n",
    "        self.branch5_conv = nn.Conv2d(in_chans, out_chans, 1, 1, 0, bias=True)\n",
    "        self.branch5_bn = nn.BatchNorm2d(out_chans)\n",
    "        self.branch5_relu = nn.ReLU(inplace=True)\n",
    "        self.conv_cat = nn.Sequential(\n",
    "            nn.Conv2d(out_chans * 5, out_chans, 1, 1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(out_chans),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        conv1x1 = self.branch1(x)\n",
    "        conv3x3_1 = self.branch2(x)\n",
    "        conv3x3_2 = self.branch3(x)\n",
    "        conv3x3_3 = self.branch4(x)\n",
    "        global_feature = self.branch5_avg(x)\n",
    "        global_feature = self.branch5_relu(self.branch5_bn(self.branch5_conv(global_feature)))\n",
    "        global_feature = F.interpolate(global_feature, (h, w), None, 'bilinear', True)\n",
    "\n",
    "        feature_cat = torch.cat([conv1x1, conv3x3_1, conv3x3_2, conv3x3_3, global_feature], dim=1)\n",
    "        result = self.conv_cat(feature_cat)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNet101v2(nn.Module):\n",
    "    '''\n",
    "    ResNet101 model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(ResNet101v2, self).__init__()\n",
    "        self.conv1 = Block(3, 64, 7, 3, 2)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
    "        self.conv2_1 =DownBottleneck(64, 256, stride=1)\n",
    "        self.conv2_2 =Bottleneck(256, 256)\n",
    "        self.conv2_3 =Bottleneck(256, 256)\n",
    "        self.layer3 = Layer(256, [512]*2, \"resnet\")\n",
    "        self.layer4 = Layer(512, [1024]*23, \"resnet\")\n",
    "        self.layer5 = Layer(1024, [2048]*3, \"resnet\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        f1 = self.conv1(x)\n",
    "        f2 = self.conv2_3(self.conv2_2(self.conv2_1(self.pool1(f1))))\n",
    "        f3 = self.layer3(f2)\n",
    "        f4 = self.layer4(f3)\n",
    "        f5 = self.layer5(f4)\n",
    "        return [f2, f3, f4, f5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bn_mom = 0.0003\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth'\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, atrous=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1 * atrous, dilation=atrous, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, stride=1, atrous=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_chans, out_chans, stride, atrous)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chans)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(out_chans, out_chans)\n",
    "        self.bn2 = nn.BatchNorm2d(out_chans)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, stride=1, atrous=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_chans, out_chans, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chans)\n",
    "        self.conv2 = nn.Conv2d(out_chans, out_chans, kernel_size=3, stride=stride,\n",
    "                               padding=1 * atrous, dilation=atrous, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_chans)\n",
    "        self.conv3 = nn.Conv2d(out_chans, out_chans * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_chans * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet_Atrous(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, atrous=None, os=16):\n",
    "        super(ResNet_Atrous, self).__init__()\n",
    "        stride_list = None\n",
    "        if os == 8:\n",
    "            stride_list = [2, 1, 1]\n",
    "        elif os == 16:\n",
    "            stride_list = [2, 2, 1]\n",
    "        else:\n",
    "            raise ValueError('resnet_atrous.py: output stride=%d is not supported.' % os)\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 256, 128, layers[1], stride=stride_list[0])\n",
    "        self.layer3 = self._make_layer(block, 512, 256, layers[2], stride=stride_list[1], atrous=16 // os)\n",
    "        self.layer4 = self._make_layer(block, 1024, 512, layers[3], stride=stride_list[2],\n",
    "                                       atrous=[item * 16 // os for item in atrous])\n",
    "        self.layer5 = self._make_layer(block, 2048, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\n",
    "        self.layer6 = self._make_layer(block, 2048, 512, layers[3], stride=1, atrous=[item*16//os for item in atrous])\n",
    "        self.layers = []\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, block, in_chans, out_chans, blocks, stride=1, atrous=None):\n",
    "        downsample = None\n",
    "        if atrous == None:\n",
    "            atrous = [1] * blocks\n",
    "        elif isinstance(atrous, int):\n",
    "            atrous_list = [atrous] * blocks\n",
    "            atrous = atrous_list\n",
    "        if stride != 1 or in_chans != out_chans * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_chans, out_chans * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_chans * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(in_chans, out_chans, stride=stride, atrous=atrous[0], downsample=downsample))\n",
    "        in_chans = out_chans*4\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(in_chans, out_chans, stride=1, atrous=atrous[i]))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layers_list = []\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        layers_list.append(x)\n",
    "        x = self.layer2(x)\n",
    "        layers_list.append(x)\n",
    "        x = self.layer3(x)\n",
    "        layers_list.append(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        layers_list.append(x)\n",
    "\n",
    "        return layers_list\n",
    "\n",
    "\n",
    "def resnet50_atrous(pretrained=True, os=16, **kwargs):\n",
    "    \"\"\"Constructs a atrous ResNet-50 model.\"\"\"\n",
    "    model = ResNet_Atrous(Bottleneck, [3, 4, 6, 3], atrous=[1, 2, 1], os=os, **kwargs)\n",
    "    if pretrained:\n",
    "        old_dict = model_zoo.load_url(model_urls['resnet50'])\n",
    "        model_dict = model.state_dict()\n",
    "        old_dict = {k: v for k, v in old_dict.items() if (k in model_dict)}\n",
    "        model_dict.update(old_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101_atrous(pretrained=True, os=16, **kwargs):\n",
    "    \"\"\"Constructs a atrous ResNet-101 model.\"\"\"\n",
    "    model = ResNet_Atrous(Bottleneck, [3, 4, 23, 3], atrous=[1, 2, 1], os=os, **kwargs)\n",
    "    if pretrained:\n",
    "        old_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "        model_dict = model.state_dict()\n",
    "        old_dict = {k: v for k, v in old_dict.items() if (k in model_dict)}\n",
    "        model_dict.update(old_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class UNetConvBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, padding, batch_norm):\n",
    "        super(UNetConvBlock, self).__init__()\n",
    "        block = []\n",
    "\n",
    "        block.append(nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_chans))\n",
    "\n",
    "        block.append(nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=int(padding)))\n",
    "        block.append(nn.ReLU())\n",
    "        if batch_norm:\n",
    "            block.append(nn.BatchNorm2d(out_chans))\n",
    "\n",
    "        self.block = nn.Sequential(*block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out\n",
    "\n",
    "class UNetUpBlock(nn.Module):\n",
    "    def __init__(self, in_chans, out_chans, up_mode, padding):\n",
    "        super(UNetUpBlock, self).__init__()\n",
    "        if up_mode == 'upconv':\n",
    "            self.up = nn.ConvTranspose2d(in_chans, out_chans, kernel_size=2, stride=2)\n",
    "        elif up_mode == 'upsample':\n",
    "            self.up = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_chans, out_chans, kernel_size=1),\n",
    "            )\n",
    "        self.conv_block = UNetConvBlock(in_chans, out_chans, padding, True)\n",
    "\n",
    "    def center_crop(self, layer, target_size):\n",
    "        _, _, layer_height, layer_width = layer.size()\n",
    "        diff_y = (layer_height - target_size[0]) // 2\n",
    "        diff_x = (layer_width - target_size[1]) // 2\n",
    "        return layer[\n",
    "               :, :, diff_y : (diff_y + target_size[0]), diff_x : (diff_x + target_size[1])\n",
    "               ]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.shape[2:])\n",
    "        out = torch.cat([crop1, up], dim=1)\n",
    "        out = self.conv_block(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            config\n",
    "    ):\n",
    "        super(ResNetUNet, self).__init__()\n",
    "        self.n_classes = config.NUM_CLASSES\n",
    "        self.padding = 1\n",
    "        self.up_mode = 'upconv'\n",
    "        assert self.up_mode in ('upconv', 'upsample')\n",
    "        self.encode = ResNet101v2()\n",
    "        prev_channels = 2048\n",
    "        self.up_path = nn.ModuleList()\n",
    "        for i in range(3):\n",
    "            self.up_path.append(\n",
    "                UNetUpBlock(prev_channels, prev_channels // 2, self.up_mode, self.padding)\n",
    "            )\n",
    "            prev_channels //= 2\n",
    "\n",
    "        self.cls_conv_block1 = Block(prev_channels, 32)\n",
    "        self.cls_conv_block2 = Block(32, 16)\n",
    "        self.last = nn.Conv2d(16, self.n_classes, kernel_size=1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_size = x.size()[2:]\n",
    "        blocks = self.encode(x)\n",
    "        x = blocks[-1]\n",
    "        for i, up in enumerate(self.up_path):\n",
    "            x = up(x, blocks[-i - 2])\n",
    "        x = nn.Upsample(size=input_size, mode='bilinear', align_corners=True)(x)\n",
    "        x = self.cls_conv_block1(x)\n",
    "        x = self.cls_conv_block2(x)\n",
    "        x = self.last(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DeeplabV3Plus(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(DeeplabV3Plus, self).__init__()\n",
    "        self.backbone = resnet50_atrous(pretrained=True, os=cfg.OUTPUT_STRIDE)\n",
    "        input_channel = 2048\n",
    "        self.aspp = ASPP(in_chans=input_channel, out_chans=cfg.ASPP_OUTDIM, rate=16//cfg.OUTPUT_STRIDE)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.upsample4 = nn.UpsamplingBilinear2d(scale_factor=4)\n",
    "        self.upsample_sub = nn.UpsamplingBilinear2d(scale_factor=cfg.OUTPUT_STRIDE//4)\n",
    "\n",
    "        indim = 256\n",
    "        self.shortcut_conv = nn.Sequential(\n",
    "            nn.Conv2d(indim, cfg.SHORTCUT_DIM, cfg.SHORTCUT_KERNEL, 1, padding=cfg.SHORTCUT_KERNEL//2,bias=False),\n",
    "            nn.BatchNorm2d(cfg.SHORTCUT_DIM),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.cat_conv = nn.Sequential(\n",
    "            nn.Conv2d(cfg.ASPP_OUTDIM+cfg.SHORTCUT_DIM, cfg.ASPP_OUTDIM, 3, 1, padding=1,bias=False),\n",
    "            nn.BatchNorm2d(cfg.ASPP_OUTDIM),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv2d(cfg.ASPP_OUTDIM, cfg.ASPP_OUTDIM, 3, 1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(cfg.ASPP_OUTDIM),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        self.cls_conv = nn.Conv2d(cfg.ASPP_OUTDIM, cfg.NUM_CLASSES, 1, 1, padding=0)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        layers = self.backbone(x)\n",
    "        feature_aspp = self.aspp(layers[-1])\n",
    "        feature_aspp = self.dropout1(feature_aspp)\n",
    "        feature_aspp = self.upsample_sub(feature_aspp)\n",
    "\n",
    "        feature_shallow = self.shortcut_conv(layers[0])\n",
    "        feature_cat = torch.cat([feature_aspp, feature_shallow],1)\n",
    "        result = self.cat_conv(feature_cat)\n",
    "        result = self.cls_conv(result)\n",
    "        result = self.upsample4(result)\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device_list = [0]\n",
    "train_net = 'deeplabv3p' # 'unet'\n",
    "nets = {'deeplabv3p': DeeplabV3Plus, 'unet': ResNetUNet}\n",
    "\n",
    "def loss_func(predict, target, nbclasses, epoch):\n",
    "    ''' can modify or add losses '''\n",
    "    ce_loss = MySoftmaxCrossEntropyLoss(nbclasses=nbclasses)(predict, target)\n",
    "    return ce_loss\n",
    "\n",
    "\n",
    "def train_epoch(net, epoch, dataLoader, optimizer, trainF, config):\n",
    "    net.train()\n",
    "    total_mask_loss = 0.0\n",
    "    dataprocess = tqdm(dataLoader)\n",
    "    for batch_item in dataprocess:\n",
    "        image, mask = batch_item['image'], batch_item['mask']\n",
    "        if torch.cuda.is_available():\n",
    "            image, mask = image.cuda(device=device_list[0]), mask.cuda(device=device_list[0])\n",
    "        optimizer.zero_grad()\n",
    "        out = net(image)\n",
    "        mask_loss = loss_func(out, mask, config.NUM_CLASSES, epoch)\n",
    "        total_mask_loss += mask_loss.item()\n",
    "        mask_loss.backward()\n",
    "        optimizer.step()\n",
    "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\n",
    "        dataprocess.set_postfix_str(\"mask_loss:{:.4f}\".format(mask_loss.item()))\n",
    "    trainF.write(\"Epoch:{}, mask loss is {:.4f} \\n\".format(epoch, total_mask_loss / len(dataLoader)))\n",
    "    trainF.flush()\n",
    "\n",
    "\n",
    "def test(net, epoch, dataLoader, testF, config):\n",
    "    net.eval()\n",
    "    total_mask_loss = 0.0\n",
    "    dataprocess = tqdm(dataLoader)\n",
    "    result = {\"TP\": {i:0 for i in range(8)}, \"TA\":{i:0 for i in range(8)}}\n",
    "    for batch_item in dataprocess:\n",
    "        image, mask = batch_item['image'], batch_item['mask']\n",
    "        if torch.cuda.is_available():\n",
    "            image, mask = image.cuda(device=device_list[0]), mask.cuda(device=device_list[0])\n",
    "        out = net(image)\n",
    "        mask_loss = loss_func(out, mask, config.NUM_CLASSES, epoch)\n",
    "        total_mask_loss += mask_loss.detach().item()\n",
    "        pred = torch.argmax(F.softmax(out, dim=1), dim=1)\n",
    "        result = compute_iou(pred, mask, result)\n",
    "        dataprocess.set_description_str(\"epoch:{}\".format(epoch))\n",
    "        dataprocess.set_postfix_str(\"mask_loss:{:.4f}\".format(mask_loss))\n",
    "    testF.write(\"Epoch:{} \\n\".format(epoch))\n",
    "    miou = 0\n",
    "    for i in range(8):\n",
    "        iou_i = result[\"TP\"][i]/result[\"TA\"][i]\n",
    "        result_string = \"{}: {:.4f} \\n\".format(i, iou_i)\n",
    "        print(result_string)\n",
    "        testF.write(result_string)\n",
    "        miou += iou_i\n",
    "    miou /= 8\n",
    "    miou_string = \"{}: {:.4f} \\n\".format('miou', miou)\n",
    "    print(miou_string)\n",
    "    testF.write(miou_string)\n",
    "    testF.write(\"Epoch:{}, mask loss is {:.4f} \\n\".format(epoch, total_mask_loss / len(dataLoader)))\n",
    "    testF.flush()\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, epoch):\n",
    "    if epoch == 4:\n",
    "        lr = 3e-4\n",
    "    elif epoch == 6:\n",
    "        lr = 5e-5\n",
    "    elif epoch == 8:\n",
    "        lr = 1e-5\n",
    "    else:\n",
    "        return\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def main():\n",
    "    lane_config = Config()\n",
    "    if os.path.exists(lane_config.SAVE_PATH):\n",
    "        shutil.rmtree(lane_config.SAVE_PATH)\n",
    "    os.makedirs(lane_config.SAVE_PATH, exist_ok=True)\n",
    "    trainF = open(os.path.join(lane_config.SAVE_PATH, \"train_log.csv\"), 'w')\n",
    "    testF = open(os.path.join(lane_config.SAVE_PATH, \"val_log.csv\"), 'w')\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "    train_dataset = LaneDataset(\"data_list/train.csv\", transform=transforms.Compose([ImageAug(), DeformAug(),\n",
    "                                                                                     ScaleAug(), CutOut(32, 0.5), ToTensor()]))\n",
    "\n",
    "    train_data_batch = DataLoader(train_dataset, batch_size=8*len(device_list), shuffle=True, drop_last=True, **kwargs)\n",
    "    val_dataset = LaneDataset(\"data_list/val.csv\", transform=transforms.Compose([ToTensor()]))\n",
    "\n",
    "    val_data_batch = DataLoader(val_dataset, batch_size=4*len(device_list), shuffle=False, drop_last=False, **kwargs)\n",
    "    net = nets[train_net](lane_config)\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda(device=device_list[0])\n",
    "        net = torch.nn.DataParallel(net, device_ids=device_list)\n",
    "    # optimizer = torch.optim.SGD(net.parameters(), lr=lane_config.BASE_LR,\n",
    "    #                             momentum=0.9, weight_decay=lane_config.WEIGHT_DECAY)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lane_config.BASE_LR, weight_decay=lane_config.WEIGHT_DECAY)\n",
    "    for epoch in range(lane_config.EPOCHS):\n",
    "        adjust_lr(optimizer, epoch)\n",
    "        train_epoch(net, epoch, train_data_batch, optimizer, trainF, lane_config)\n",
    "        test(net, epoch, val_data_batch, testF, lane_config)\n",
    "        torch.save({'state_dict': net.state_dict()}, os.path.join(os.getcwd(), lane_config.SAVE_PATH, \"laneNet{}.pth.tar\".format(epoch)))\n",
    "    trainF.close()\n",
    "    testF.close()\n",
    "    torch.save({'state_dict': net.state_dict()}, os.path.join(os.getcwd(), lane_config.SAVE_PATH, \"finalNet.pth.tar\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device_id = 0\n",
    "predict_net = 'deeplabv3p'\n",
    "nets = {'deeplabv3p': DeeplabV3Plus, 'unet': ResNetUNet}\n",
    "\n",
    "def load_model(model_path):\n",
    "\n",
    "    lane_config = Config()\n",
    "    net = nets[predict_net](lane_config)\n",
    "    net.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda(device=device_id)\n",
    "        map_location = 'cuda:%d' % device_id\n",
    "    else:\n",
    "        map_location = 'cpu'\n",
    "\n",
    "    model_param = torch.load(model_path, map_location=map_location)['state_dict']\n",
    "    model_param = {k.replace('module.', ''):v for k, v in model_param.items()}\n",
    "    net.load_state_dict(model_param)\n",
    "    return net\n",
    "\n",
    "\n",
    "def img_transform(img):\n",
    "    img = crop_resize_data(img)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = img[np.newaxis, ...].astype(np.float32)\n",
    "    img = torch.from_numpy(img.copy())\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda(device=device_id)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_color_mask(pred):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    pred = torch.squeeze(pred)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    pred = decode_color_labels(pred)\n",
    "    pred = np.transpose(pred, (1, 2, 0))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def main():\n",
    "    test_dir = 'test_example'\n",
    "    model_path = os.path.join(test_dir, predict_net + '_finalNet.pth.tar')\n",
    "    print('Loading model...')\n",
    "    net = load_model(model_path)\n",
    "    print('Finished.')\n",
    "\n",
    "    img_path = os.path.join(test_dir, 'test.jpg')\n",
    "    img = cv2.imread(img_path)\n",
    "    img = img_transform(img)\n",
    "\n",
    "    print('Model infering...')\n",
    "    pred = net(img)\n",
    "    color_mask = get_color_mask(pred)\n",
    "    cv2.imwrite(os.path.join(test_dir, 'color_mask.jpg'), color_mask)\n",
    "    print('Finished')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "\n",
    "    lane_config = Config()\n",
    "    net = nets[predict_net](lane_config)\n",
    "    net.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda(device=device_id)\n",
    "        map_location = 'cuda:%d' % device_id\n",
    "    else:\n",
    "        map_location = 'cpu'\n",
    "\n",
    "    model_param = torch.load(model_path, map_location=map_location)['state_dict']\n",
    "    # module.\n",
    "    model_param = {k.replace('module.', ''):v for k, v in model_param.items()}\n",
    "    net.load_state_dict(model_param)\n",
    "    return net\n",
    "\n",
    "\n",
    "def img_transform(img):\n",
    "    img = crop_resize_data(img)\n",
    "    img = np.transpose(img, (2, 0, 1))\n",
    "    img = img[np.newaxis, ...].astype(np.float32)\n",
    "    img = torch.from_numpy(img.copy())\n",
    "    if torch.cuda.is_available():\n",
    "        img = img.cuda(device=device_id)\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_color_mask(pred):\n",
    "    pred = torch.softmax(pred, dim=1)\n",
    "    pred = torch.argmax(pred, dim=1)\n",
    "    pred = torch.squeeze(pred)\n",
    "    pred = pred.detach().cpu().numpy()\n",
    "    pred = decode_color_labels(pred)\n",
    "    pred = np.transpose(pred, (1, 2, 0))\n",
    "    return pred\n",
    "\n",
    "\n",
    "def resize_padding(pred, image_size=(3384, 1020), offset=690):\n",
    "    pred = cv2.resize(pred, image_size, interpolation=cv2.INTER_NEAREST)\n",
    "    padding = np.zeros((offset, image_size[0], 3), dtype=np.uint8)\n",
    "    pred = np.concatenate([padding, pred], axis=0)\n",
    "    return pred\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "device_id = 0\n",
    "predict_net = 'deeplabv3p'\n",
    "nets = {'deeplabv3p': DeeplabV3Plus, 'unet': ResNetUNet}\n",
    "\n",
    "test_dir = 'test_example'\n",
    "model_path = os.path.join(test_dir, predict_net + '_finalNet.pth.tar')\n",
    "print('Loading model...')\n",
    "net = load_model(model_path)\n",
    "net.eval()\n",
    "print('Finished.')\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index_page():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/infer', methods = ['GET', 'POST'])\n",
    "def infer():\n",
    "    if request.method == 'POST':\n",
    "        f = request.files['file']\n",
    "        img = Image.open(BytesIO(f.read()))\n",
    "        img = np.asarray(img)[..., ::-1]\n",
    "        img = img_transform(img)\n",
    "        print('Model infering...')\n",
    "        pred = net(img)\n",
    "        color_mask = get_color_mask(pred)\n",
    "        color_mask = resize_padding(color_mask)\n",
    "        color_mask = Image.fromarray(color_mask[..., ::-1])\n",
    "        print('Finished')\n",
    "        output_buffer = BytesIO()\n",
    "        color_mask.save(output_buffer, format='JPEG')\n",
    "        byte_data = output_buffer.getvalue()\n",
    "        b64data = base64.b64encode(byte_data).decode('utf-8')\n",
    "        return render_template('show_result.html', b64data=b64data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}